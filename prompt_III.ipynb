{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The data represents 17 campaigns from May 2008 to November 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.3.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "%pip install seaborn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pylot'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpylot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib.pylot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full_df = pd.read_csv('./data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_unknown_job 330\n",
      "num_unknown_marital 80\n",
      "num_unknown_education 1731\n",
      "num_unknown_default 8597\n",
      "num_unknown_housing 990\n",
      "num_unknown_loan 990\n",
      "rows_with_missing_data Empty DataFrame\n",
      "Columns: [age, job, marital, education, default, housing, loan, contact, month, day_of_week, duration, campaign, pdays, previous, poutcome, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed, y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Number of rows with \"unknown\" value\n",
    "num_unknown_job = (bank_full_df['job'] == 'unknown').sum() # 330\n",
    "print('num_unknown_job', num_unknown_job)\n",
    "\n",
    "num_unknown_marital = (bank_full_df['marital'] == 'unknown').sum() # 80\n",
    "print('num_unknown_marital', num_unknown_marital)\n",
    "\n",
    "num_unknown_education = (bank_full_df['education'] == 'unknown').sum() # 1731\n",
    "print('num_unknown_education', num_unknown_education)\n",
    "\n",
    "num_unknown_default = (bank_full_df['default'] == 'unknown').sum() # 8597\n",
    "print('num_unknown_default', num_unknown_default)\n",
    "\n",
    "num_unknown_housing = (bank_full_df['housing'] == 'unknown').sum() # 990\n",
    "print('num_unknown_housing', num_unknown_housing)\n",
    "\n",
    "num_unknown_loan = (bank_full_df['loan'] == 'unknown').sum() # 990\n",
    "print('num_unknown_loan', num_unknown_loan)\n",
    "\n",
    "# Rows with missing values\n",
    "rows_with_missing_data = bank_full_df[bank_full_df.isnull().any(axis=1)]\n",
    "print('rows_with_missing_data', rows_with_missing_data) # No rows are missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'month' column to one of four seasons 'winter' (Dec, Jan, Feb), 'spring', (March, April, May), 'summer' (June, July, Aug), 'fall' (Sept, Oct, Nov)\n",
    "def categorize_season(month):\n",
    "    if month in ['dec', 'jan', 'feb']:\n",
    "        return 'winter'\n",
    "    elif month in ['mar', 'apr', 'may']:\n",
    "        return 'spring'\n",
    "    elif month in ['jun', 'jul', 'aug']:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "def categorize_age(age):\n",
    "    if age < 30:\n",
    "        return '<30'\n",
    "    elif age >= 30 and age < 50:\n",
    "        return '30-49'\n",
    "    elif age >= 50 and age < 70:\n",
    "        return '50-69'\n",
    "    elif age >= 70 and age < 90:\n",
    "        return '70-89'\n",
    "    else:\n",
    "        return '>90'\n",
    "\n",
    "def categorize_pdays(pdays):\n",
    "    if pdays >= 0 and pdays < 5:\n",
    "        return '0-4'\n",
    "    elif pdays >= 5 and pdays < 10:\n",
    "        return '5-9'\n",
    "    elif pdays >= 10 and pdays < 15:\n",
    "        return '10-14'\n",
    "    elif pdays >= 15 and pdays < 20:\n",
    "        return '15-19'\n",
    "    elif pdays >= 20 and pdays < 25:\n",
    "        return '20-24'\n",
    "    elif pdays >= 25 and pdays < 30:\n",
    "        return '25-29'\n",
    "    else:\n",
    "        return 'not_prev_contacted'\n",
    "\n",
    "\n",
    "def clean_df_data(df):\n",
    "    # Remove rows with \"unknown\" value\n",
    "    clean_df = df[df['job'] != 'unknown']\n",
    "    clean_df = clean_df[clean_df['marital'] != 'unknown']\n",
    "    clean_df = clean_df[clean_df['education'] != 'unknown']\n",
    "    clean_df = clean_df[clean_df['default'] != 'unknown']\n",
    "    clean_df = clean_df[clean_df['housing'] != 'unknown']\n",
    "    clean_df = clean_df[clean_df['loan'] != 'unknown']\n",
    "\n",
    "    # Remove \"duration\" column based on description above for better predictive model\n",
    "    clean_df = clean_df.drop('duration', axis=1)\n",
    "\n",
    "    # convert month to season\n",
    "    clean_df['season'] = clean_df['month'].apply(categorize_season)\n",
    "    # Drop month because it's now represented as season\n",
    "    clean_df = clean_df.drop('month', axis=1)\n",
    "    \n",
    "    # convert pdays to pdays_range. Initial values from whole dataset 0 - 27 and 999\n",
    "    clean_df['pdays_range'] = clean_df['pdays'].apply(categorize_pdays)\n",
    "    clean_df['pdays_range'].unique()\n",
    "    # Drop pdays because it's now represented as pdays_range\n",
    "    clean_df = clean_df.drop('pdays', axis=1)\n",
    "\n",
    "    # convert age to range. Initial values from whole dataset 17 - 95\n",
    "    clean_df['age_range'] = clean_df['age'].apply(categorize_age)\n",
    "    # Drop age because it's now represented as age_range\n",
    "    clean_df = clean_df.drop('age', axis=1)\n",
    "    return clean_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Business Object is to analyze the data from 17 marketing campaigns to identify key factors\n",
    "that influence client decisions, and create a predictive model that accurately predicts whether a\n",
    "prospective client will subscribe to a term deposit. The bank will be able to use this model and \n",
    "information to create effective and efficient campaign strategies that increase subscriptions to term deposits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_columns ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day_of_week', 'poutcome', 'season', 'pdays_range', 'age_range']\n",
      "numerical_columns ['campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n"
     ]
    }
   ],
   "source": [
    "clean_bank_full_df=clean_df_data(bank_full_df)\n",
    "\n",
    "X = clean_bank_full_df.drop('y', axis=1)\n",
    "y = clean_bank_full_df.y\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "print('categorical_columns', categorical_columns)\n",
    "print('numerical_columns', numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes the data based on whether it's numerical or categorical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The classifier should ideally accurately predict whether a client will subscribe to a term deposit 90% of the time.\n",
    "This level of accuracy would provide the bank with significant power to target clients most likely to convert while \n",
    "recognizing that inaccurate estimates is not exorbinantly expensive either monetarily or consequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.5651466051737468\n",
      "best_model Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['campaign', 'previous',\n",
      "                                                   'emp.var.rate',\n",
      "                                                   'cons.price.idx',\n",
      "                                                   'cons.conf.idx', 'euribor3m',\n",
      "                                                   'nr.employed']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(drop='first'),\n",
      "                                                  ['job', 'marital',\n",
      "                                                   'education', 'default',\n",
      "                                                   'housing', 'loan', 'contact',\n",
      "                                                   'day_of_week', 'poutcome',\n",
      "                                                   'season', 'pdays_range',\n",
      "                                                   'age_range'])])),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.1, max_iter=500))])\n",
      "train_score 0.8893808938089381\n",
      "test_score 0.8868481469334208\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logisticregression', LogisticRegression(max_iter=500))\n",
    "])\n",
    "    \n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid={'logisticregression__C': [0.1, 1, 10]}, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "# Fit the model and time it\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print('fit_time', fit_time)\n",
    "print('best_model', best_model)\n",
    "print('train_score', train_score)\n",
    "print('test_score', test_score)\n",
    "logistic_regression_result={ \"model\": \"Logistic Regression\", \"train_time\": fit_time, \"train_accuracy\": train_score, \"test_accuracy\": test_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The model was 88.68% accurate on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 14.103101968765259\n",
      "best_model Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['campaign', 'previous',\n",
      "                                                   'emp.var.rate',\n",
      "                                                   'cons.price.idx',\n",
      "                                                   'cons.conf.idx', 'euribor3m',\n",
      "                                                   'nr.employed']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(drop='first'),\n",
      "                                                  ['job', 'marital',\n",
      "                                                   'education', 'default',\n",
      "                                                   'housing', 'loan', 'contact',\n",
      "                                                   'day_of_week', 'poutcome',\n",
      "                                                   'season', 'pdays_range',\n",
      "                                                   'age_range'])])),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=7))])\n",
      "train_score 0.8987289872898729\n",
      "test_score 0.8752049852410626\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "    \n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid={'knn__n_neighbors': [3, 5, 7]}, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "# Fit the model and time it\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print('fit_time', fit_time)\n",
    "print('best_model', best_model)\n",
    "print('train_score', train_score)\n",
    "print('test_score', test_score)\n",
    "knn_result={ \"model\": \"KNN\", \"train_time\": fit_time, \"train_accuracy\": train_score, \"test_accuracy\": test_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.3018353780110677\n",
      "best_model Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['campaign', 'previous',\n",
      "                                                   'emp.var.rate',\n",
      "                                                   'cons.price.idx',\n",
      "                                                   'cons.conf.idx', 'euribor3m',\n",
      "                                                   'nr.employed']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(drop='first'),\n",
      "                                                  ['job', 'marital',\n",
      "                                                   'education', 'default',\n",
      "                                                   'housing', 'loan', 'contact',\n",
      "                                                   'day_of_week', 'poutcome',\n",
      "                                                   'season', 'pdays_range',\n",
      "                                                   'age_range'])])),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(max_depth=5))])\n",
      "train_score 0.8920049200492005\n",
      "test_score 0.8850442768120695\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('decisiontreeclassifier', DecisionTreeClassifier())\n",
    "])\n",
    "    \n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid={'decisiontreeclassifier__max_depth': [2, 5, 7]}, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "# Fit the model and time it\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print('fit_time', fit_time)\n",
    "print('best_model', best_model)\n",
    "print('train_score', train_score)\n",
    "print('test_score', test_score)\n",
    "decision_tree_classifier_result={ \"model\": \"Decision Tree Classifier\", \"train_time\": fit_time, \"train_accuracy\": train_score, \"test_accuracy\": test_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day_of_week',\n",
       " 'poutcome',\n",
       " 'season',\n",
       " 'pdays_range',\n",
       " 'age_range']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the smaller data sample for the SVC because it's computationally demanding\n",
    "bank_additional_df = pd.read_csv('./data/bank-additional.csv', sep = ';')\n",
    "\n",
    "clean_bank_additional_df=clean_df_data(bank_additional_df)\n",
    "\n",
    "X_additional = clean_bank_additional_df.drop('y', axis=1)\n",
    "y_additional = clean_bank_additional_df.y\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_additional = le.fit_transform(y_additional)\n",
    "categorical_columns = X_additional.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = X_additional.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns) # Ignoring unknown because this is a subset of the whole data\n",
    "    ]\n",
    ")\n",
    "X_additional_train, X_additional_test, y_additional_train, y_additional_test = train_test_split(X_additional, y_additional, test_size=0.2, random_state=42)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [10] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [10] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [10] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [10] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [10] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [10] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.1742851734161377\n",
      "best_model Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['campaign', 'previous',\n",
      "                                                   'emp.var.rate',\n",
      "                                                   'cons.price.idx',\n",
      "                                                   'cons.conf.idx', 'euribor3m',\n",
      "                                                   'nr.employed']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(drop='first',\n",
      "                                                                handle_unknown='ignore'),\n",
      "                                                  ['job', 'marital',\n",
      "                                                   'education', 'default',\n",
      "                                                   'housing', 'loan', 'contact',\n",
      "                                                   'day_of_week', 'poutcome',\n",
      "                                                   'season', 'pdays_range',\n",
      "                                                   'age_range'])])),\n",
      "                ('svc', SVC(C=0.1, kernel='linear'))])\n",
      "train_score 0.886326860841424\n",
      "test_score 0.9142394822006472\n"
     ]
    }
   ],
   "source": [
    "# SVC Processor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "    \n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid={'svc__C': [0.1, 1, 10], 'svc__kernel': ['linear', 'rbf']}, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "# Fit the model and time it\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_additional_train, y_additional_train)\n",
    "fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "train_score = best_model.score(X_additional_train, y_additional_train)\n",
    "test_score = best_model.score(X_additional_test, y_additional_test)\n",
    "print('fit_time', fit_time)\n",
    "print('best_model', best_model)\n",
    "print('train_score', train_score)\n",
    "print('test_score', test_score)\n",
    "svc_result={ \"model\": \"SVC\", \"train_time\": fit_time, \"train_accuracy\": train_score, \"test_accuracy\": test_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.565147</td>\n",
       "      <td>0.889381</td>\n",
       "      <td>0.886848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>14.103102</td>\n",
       "      <td>0.898729</td>\n",
       "      <td>0.875205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.301835</td>\n",
       "      <td>0.892005</td>\n",
       "      <td>0.885044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.174285</td>\n",
       "      <td>0.886327</td>\n",
       "      <td>0.914239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  train_time  train_accuracy  test_accuracy\n",
       "0       Logistic Regression    1.565147        0.889381       0.886848\n",
       "1                       KNN   14.103102        0.898729       0.875205\n",
       "2  Decision Tree Classifier    0.301835        0.892005       0.885044\n",
       "3                       SVC    0.174285        0.886327       0.914239"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results=[logistic_regression_result, knn_result, decision_tree_classifier_result, svc_result]\n",
    "result_df = pd.DataFrame(all_results)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the impact of different features\n",
    "clean_all_df=clean_df_data(bank_full_df)\n",
    "\n",
    "def add_default_prefix(word):\n",
    "    return \"default_\" + word\n",
    "def add_housing_prefix(word):\n",
    "    return \"housing_\" + word\n",
    "def add_loan_prefix(word):\n",
    "    return \"loan_\" + word\n",
    "\n",
    "clean_all_df['default'] = clean_all_df['default'].apply(add_default_prefix)\n",
    "clean_all_df['housing'] = clean_all_df['housing'].apply(add_housing_prefix)\n",
    "clean_all_df['loan'] = clean_all_df['loan'].apply(add_loan_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the impact of different features\n",
    "dummies_job=pd.get_dummies(clean_all_df['job'], dtype=int)\n",
    "dummies_marital=pd.get_dummies(clean_all_df['marital'], dtype=int)\n",
    "dummies_education=pd.get_dummies(clean_all_df['education'], dtype=int)\n",
    "dummies_default=pd.get_dummies(clean_all_df['default'], dtype=int)\n",
    "dummies_housing=pd.get_dummies(clean_all_df['housing'], dtype=int)\n",
    "dummies_loan=pd.get_dummies(clean_all_df['loan'], dtype=int)\n",
    "dummies_contact=pd.get_dummies(clean_all_df['contact'], dtype=int)\n",
    "dummies_day_of_week=pd.get_dummies(clean_all_df['day_of_week'], dtype=int)\n",
    "dummies_poutcome=pd.get_dummies(clean_all_df['poutcome'], dtype=int)\n",
    "dummies_season=pd.get_dummies(clean_all_df['season'], dtype=int)\n",
    "dummies_pdays_range=pd.get_dummies(clean_all_df['pdays_range'], dtype=int)\n",
    "dummies_age_range=pd.get_dummies(clean_all_df['age_range'], dtype=int)\n",
    "df = pd.concat([dummies_job, dummies_marital, dummies_education, dummies_default, dummies_housing, dummies_loan, dummies_contact, dummies_day_of_week, dummies_poutcome, dummies_season, dummies_pdays_range, dummies_age_range], axis=1)\n",
    "clean_all_df['y']=np.where(clean_all_df['y'] == 'no', 0, 1)\n",
    "y=clean_all_df['y']\n",
    "y.head(5)\n",
    "X_lasso_train, X_lasso_test, y_lasso_train, y_lasso_test=train_test_split(df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the impact of different features\n",
    "pipe = Pipeline([\n",
    "    ('polyfeatures', PolynomialFeatures(degree = 3, include_bias = False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(random_state=42))\n",
    "])\n",
    "pipe.fit(X_lasso_train, y_lasso_train)\n",
    "lasso_coefs=pipe.named_steps['lasso'].coef_\n",
    "feature_names=pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "lasso_df=pd.DataFrame({ 'feature': feature_names, 'coef': lasso_coefs })\n",
    "results=lasso_df.loc[lasso_df['coef'] != 0]\n",
    "sorted = results.sort_values(by='coef', ascending=False)\n",
    "print(sorted.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
